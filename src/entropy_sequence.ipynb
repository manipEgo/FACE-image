{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pygam import LinearGAM\n",
    "from scipy.stats import entropy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = \"/nas/Public/experiment_result/FACE-image/img-vanGogh_est-diffusionV2/origin/\"\n",
    "generated_paths = [\n",
    "    \"/nas/Public/experiment_result/FACE-image/img-vanGogh_est-diffusionV2/v2-1_768-ema-pruned/\",\n",
    "    \"/nas/Public/experiment_result/FACE-image/img-vanGogh_est-diffusionV2/vanGoghDiffusion_v1/\",\n",
    "    \"/nas/Public/experiment_result/FACE-image/img-vanGogh_est-diffusionV2/juggernautXL_juggernautX/\"\n",
    "]\n",
    "\n",
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "SPLIT = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dict = {}\n",
    "\n",
    "for root, dirs, files in os.walk(origin_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            origin_dict.update({file.split('.')[0]: cv2.imread(os.path.join(root, file))[:, :, ::-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each subject model\n",
    "for generated_path in generated_paths:\n",
    "    print(\"listing path:\", generated_path)\n",
    "    sequences = {}\n",
    "    # # each origin image\n",
    "    # for name, origin in tqdm(origin_dict.items()):\n",
    "    #     sequence = []\n",
    "    #     # each mask strip\n",
    "    #     for mask_idx in range(SPLIT - 1):\n",
    "    #         generated_img = cv2.imread(os.path.join(generated_path, name + f\"_mask-{mask_idx}.png\"))[:, :, ::-1]\n",
    "    #         # one strip\n",
    "    #         columns = WIDTH // SPLIT * (mask_idx + 1)\n",
    "    #         token = np.array(generated_img[:, columns:columns + WIDTH // SPLIT], dtype=np.int16)\n",
    "    #         ground_truth = np.array(origin[:, columns:columns + WIDTH // SPLIT], dtype=np.int16)\n",
    "\n",
    "    #         mse = ((token - ground_truth) ** 2).mean()\n",
    "    #         sequence.append(mse)\n",
    "    #     sequences.update({name: sequence})\n",
    "    # # save entropies\n",
    "    # with open(generated_path + \"image_entropies.txt\", \"w\") as f:\n",
    "    #     for name, sequence in sequences.items():\n",
    "    #         f.write(f\"{name} {sequence}\\n\")\n",
    "    # each subject image\n",
    "    for idx in tqdm(range(len(origin_dict))):\n",
    "        subject_img = cv2.imread(os.path.join(generated_path, f\"subject-{idx}.png\"))[:, :, ::-1]\n",
    "        sequence = []\n",
    "        # each mask strip\n",
    "        for mask_idx in range(SPLIT - 1):\n",
    "            generated_img = cv2.imread(os.path.join(generated_path, f\"subject-{idx}_mask-{mask_idx}.png\"))[:, :, ::-1]\n",
    "            # one strip\n",
    "            columns = WIDTH // SPLIT * (mask_idx + 1)\n",
    "            token = np.array(generated_img[:, columns:columns + WIDTH // SPLIT], dtype=np.int16)\n",
    "            ground_truth = np.array(subject_img[:, columns:columns + WIDTH // SPLIT], dtype=np.int16)\n",
    "\n",
    "            mse = ((token - ground_truth) ** 2).mean()\n",
    "            sequence.append(mse)\n",
    "        sequences.update({f\"subject-{idx}\": sequence})\n",
    "    # save entropies\n",
    "    with open(generated_path + \"subject_entropies.txt\", \"w\") as f:\n",
    "        for name, sequence in sequences.items():\n",
    "            f.write(f\"{name} {sequence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read entropies\n",
    "image_sequences_dict = {}\n",
    "image_spectra_dict = {}\n",
    "subject_sequences_dict = {}\n",
    "subject_spectra_dict = {}\n",
    "path_names = set()\n",
    "\n",
    "for generated_path in generated_paths:\n",
    "    with open(generated_path + \"image_entropies.txt\", \"r\") as f:\n",
    "        sequences = {}\n",
    "        spectra = {}\n",
    "        for line in f:\n",
    "            name, sequence = line.split('[')\n",
    "            name = name.strip()\n",
    "            sequence = [float(x) for x in sequence.strip().strip(']').split(', ') if x]\n",
    "            spectrum = np.abs(np.fft.fft(sequence))\n",
    "            sequences.update({name: sequence})\n",
    "            spectra.update({name: spectrum})\n",
    "        path_name = generated_path.split('/')[-2]\n",
    "        image_sequences_dict.update({path_name: sequences})\n",
    "        image_spectra_dict.update({path_name: spectra})\n",
    "        path_names.add(path_name)\n",
    "    with open(generated_path + \"subject_entropies.txt\", \"r\") as f:\n",
    "        sequences = {}\n",
    "        spectra = {}\n",
    "        for line in f:\n",
    "            name, sequence = line.split('[')\n",
    "            name = name.strip()\n",
    "            sequence = [float(x) for x in sequence.strip().strip(']').split(', ') if x]\n",
    "            spectrum = np.abs(np.fft.fft(sequence))\n",
    "            sequences.update({name: sequence})\n",
    "            spectra.update({name: spectrum})\n",
    "        path_name = generated_path.split('/')[-2]\n",
    "        subject_sequences_dict.update({path_name: sequences})\n",
    "        subject_spectra_dict.update({path_name: spectra})\n",
    "        path_names.add(path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean spectra\n",
    "plt.style.use(\"default\")\n",
    "for path_name in path_names:\n",
    "    # normalized mean spectrum\n",
    "    mean_image_spectrum = np.mean([spectrum / np.linalg.norm(spectrum) for _, spectrum in image_spectra_dict[path_name].items()], axis=0)\n",
    "    mean_subject_spectrum = np.mean([spectrum / np.linalg.norm(spectrum) for _, spectrum in subject_spectra_dict[path_name].items()], axis=0)\n",
    "\n",
    "    mean_image_spectrum = mean_image_spectrum[1:]\n",
    "    mean_subject_spectrum = mean_subject_spectrum[1:]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(mean_image_spectrum, label=\"Mean Spectrum ground truth\".format(legend=path_name))\n",
    "    plt.plot(mean_subject_spectrum, label=\"Mean Spectrum {legend}\".format(legend=path_name))\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./img/spectra/{path_name}_raw.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.figure()\n",
    "    X = np.linspace(0, 0.5, len(mean_image_spectrum))\n",
    "    gam = LinearGAM().fit(X, mean_image_spectrum)\n",
    "    XX = gam.generate_X_grid(term=0, n=len(mean_image_spectrum))\n",
    "    pdep, confi = gam.partial_dependence(term=0, X=XX, width=0.95)\n",
    "    plt.plot(\n",
    "        XX[:, 0],\n",
    "        np.abs(pdep),\n",
    "        label=\"Partial Dependence ground truth\".format(legend=path_name),\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        XX[:, 0],\n",
    "        np.where(\n",
    "            confi[:, 0] * confi[:, 1] > 0,\n",
    "            np.minimum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "            0\n",
    "        ),\n",
    "        np.maximum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "        alpha=0.25\n",
    "    )\n",
    "    X = np.linspace(0, 0.5, len(mean_subject_spectrum))\n",
    "    gam = LinearGAM().fit(X, mean_subject_spectrum)\n",
    "    XX = gam.generate_X_grid(term=0, n=len(mean_subject_spectrum))\n",
    "    pdep, confi = gam.partial_dependence(term=0, X=XX, width=0.95)\n",
    "    plt.plot(\n",
    "        XX[:, 0],\n",
    "        np.abs(pdep),\n",
    "        label=\"Partial Dependence {legend}\".format(legend=path_name),\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        XX[:, 0],\n",
    "        np.where(\n",
    "            confi[:, 0] * confi[:, 1] > 0,\n",
    "            np.minimum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "            0\n",
    "        ),\n",
    "        np.maximum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "        alpha=0.25\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./img/spectra/{path_name}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_overlap(spectrum1, spectrum2):\n",
    "    spectra = np.concatenate([spectrum1[None], spectrum2[None]], axis=0)\n",
    "    return spectra.min(axis=0).sum() / spectra.max(axis=0).sum()\n",
    "\n",
    "def pearson_correlation(spectrum1, spectrum2):\n",
    "    return np.corrcoef(spectrum1, spectrum2)[0, 1]\n",
    "\n",
    "def earth_mover_distance(spectrum1, spectrum2):\n",
    "    p1 = [spectrum1[0]]\n",
    "    p2 = [spectrum2[0]]\n",
    "    for value in spectrum1[1:]:\n",
    "        p1.append(p1[-1] + value)\n",
    "    for value in spectrum2[1:]:\n",
    "        p2.append(p2[-1] + value)\n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    p1 /= p1[-1]\n",
    "    p2 /= p2[-1]\n",
    "    return np.abs(p1 - p2).sum() / spectrum1.shape[0]\n",
    "\n",
    "def kl_divergence(spectrum1, spectrum2):\n",
    "    kl = entropy(abs(spectrum1), abs(spectrum2))\n",
    "    return kl\n",
    "\n",
    "def score(spectrum1, spectrum2):\n",
    "    so = spectral_overlap(spectrum1, spectrum2)\n",
    "    corr = pearson_correlation(spectrum1, spectrum2)\n",
    "    emd = earth_mover_distance(spectrum1, spectrum2)\n",
    "    kl = kl_divergence(spectrum1, spectrum2)\n",
    "    return so, corr, emd, kl\n",
    "\n",
    "def area_under_curve(spectrum):\n",
    "    return np.abs(spectrum).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACE scores\n",
    "# estimator_name = \"v2-1_768-ema-pruned\"\n",
    "# estimator_spectrum = np.mean([spectrum / np.linalg.norm(spectrum) for _, spectrum in image_spectra_dict[estimator_name].items()], axis=0)\n",
    "# estimator_spectrum = estimator_spectrum[1:]\n",
    "for path_name in path_names:\n",
    "    # normalized mean spectrum\n",
    "    mean_image_spectrum = np.mean([spectrum / np.linalg.norm(spectrum) for _, spectrum in image_spectra_dict[path_name].items()], axis=0)\n",
    "    mean_subject_spectrum = np.mean([spectrum / np.linalg.norm(spectrum) for _, spectrum in subject_spectra_dict[path_name].items()], axis=0)\n",
    "    # mean_spectrum = mean_spectrum[1:]\n",
    "    so, corr, emd, kl = score(mean_subject_spectrum, mean_image_spectrum)\n",
    "    auc = area_under_curve(mean_subject_spectrum)\n",
    "    print('=' * 20)\n",
    "    print(path_name)\n",
    "    print(\"Spectral Overlap:\", so)\n",
    "    print(\"Pearson Correlation:\", corr)\n",
    "    print(\"Earth Mover Distance:\", emd)\n",
    "    print(\"KL Divergence:\", kl)\n",
    "    print(\"Area Under Curve:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"/nas/Public/experiment_result/FACE-image/img-vanGogh_est-diffusionV2/origin/rename/\"\n",
    "\n",
    "# for filename, img in origin_dict.items():\n",
    "#     idx = int(filename.split('-')[-1])\n",
    "#     name = filename.split('-')[0] + '-' + str(idx - 1)\n",
    "#     cv2.imwrite(os.path.join(save_path, name + \".png\"), img[:, :, ::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
