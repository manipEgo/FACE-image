{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_path = \"../img/Outline/\"\n",
    "# Get the folder information\n",
    "info = load_folder_information(img_path)\n",
    "# Generate masks\n",
    "origin = load_image(os.path.join(img_path, info[\"origin\"]))\n",
    "\n",
    "print(info)\n",
    "plt.imshow(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_num = len(info[\"mask_prefix\"])\n",
    "masks = []\n",
    "for i in range(mask_num):\n",
    "    mask = np.zeros_like(origin)\n",
    "    masked_column = origin.shape[1] // (mask_num + 1) * (i + 1)\n",
    "    mask[:, masked_column:] = 1\n",
    "    masks.append(mask)\n",
    "\n",
    "# for line in range(masks[0].shape[0]):\n",
    "#     for column in range(masks[0].shape[1]):\n",
    "#         print(masks[0][line][column][0], end=\" \")\n",
    "#     print()\n",
    "plt.imshow(masks[6]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image files\n",
    "img_names = os.listdir(img_path)\n",
    "# MSE\n",
    "logits = []\n",
    "for i in range(mask_num):\n",
    "    mask = masks[i]\n",
    "    # for line in range(mask.shape[0]):\n",
    "    #     for column in range(mask.shape[1]):\n",
    "    #         print(mask[line][column][0], end=\" \")\n",
    "    #     print()\n",
    "    mask_prefix = info[\"mask_prefix\"][i]\n",
    "    imgs = [\n",
    "        load_image(os.path.join(img_path, img_name))\n",
    "        for img_name in img_names\n",
    "        if mask_prefix in img_name\n",
    "    ]\n",
    "    mse = [image_MSE(origin, img, mask) for img in imgs]\n",
    "    logits.append(np.mean(mse))\n",
    "    # for img in imgs:\n",
    "    #     plt.imshow(img)\n",
    "    #     plt.show()\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd_path = \"/nas/Public/data/HPDv2/test/\"\n",
    "save_path = \"/home/lyy/Repos/FACE-image/data/\"\n",
    "\n",
    "import os\n",
    "\n",
    "file_list = []\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for file in os.listdir(hpd_path):\n",
    "    os.symlink(os.path.join(hpd_path, file), os.path.join(save_path, f\"image-{int(file.split('.')[0])}.\" + file.split(\".\")[-1] if file.split(\".\")[-1] != \"\" else \"jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pygam import LinearGAM\n",
    "\n",
    "SPLIT = 64\n",
    "WIDTH = 512\n",
    "MODEL_NUMBER = 9\n",
    "\n",
    "hpd_path = \"/nas/Public/data/HPDv2/test/\"\n",
    "generate_path = \"/nas/Public/experiment_result/FACE-image/\"\n",
    "mapping_path = \"/nas/Public/data/HPDv2/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = json.load(open(mapping_path))\n",
    "files = os.listdir(generate_path)\n",
    "\n",
    "groups = []\n",
    "winners = []\n",
    "counters = {}\n",
    "for i in range(MODEL_NUMBER):\n",
    "    counters[i] = {}\n",
    "    for j in range(MODEL_NUMBER):\n",
    "        counters[i][j] = 0\n",
    "rank_lists = {}\n",
    "for i in range(MODEL_NUMBER):\n",
    "    rank_lists[i] = []\n",
    "\n",
    "for item in mapping:\n",
    "    group_complete = True\n",
    "    if len(item[\"image_path\"]) != MODEL_NUMBER:\n",
    "        # cannot determine which models are used\n",
    "        continue\n",
    "    for path in item[\"image_path\"]:\n",
    "        # iterate image numbers\n",
    "        number = int(path.split('.')[0])\n",
    "        single_complete = True\n",
    "        for i in range(SPLIT-1):\n",
    "            # check each mask re-generation\n",
    "            if (f\"image-{number}_mask-{i}_00001_.png\") not in files:\n",
    "                single_complete = False\n",
    "                break\n",
    "        if not single_complete:\n",
    "            group_complete = False\n",
    "            break\n",
    "    if group_complete:\n",
    "        groups.append(item[\"image_path\"])\n",
    "        idx = 0\n",
    "        for i, rank in enumerate(item[\"rank\"]):\n",
    "            if rank == 0:\n",
    "                idx = i\n",
    "            for j in range(rank, MODEL_NUMBER):\n",
    "                counters[i][j] += 1\n",
    "        for i, rank in enumerate(item[\"rank\"]):\n",
    "            rank_lists[i].append(rank)\n",
    "        winners.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(groups))\n",
    "print(groups[0])\n",
    "print(winners)\n",
    "for i in range(MODEL_NUMBER):\n",
    "    for j, count in counters[i].items():\n",
    "        print(f\"{j}: {count}\\t\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for names in groups:\n",
    "#     for idx, name in enumerate(names):\n",
    "#         for mask in range(SPLIT-1):\n",
    "#             no = int(name.split('.')[0])\n",
    "#             os.symlink(os.path.join(generate_path, f\"image-{no}_mask-{mask}_00001_.png\"), os.path.join(f\"../data/model_{idx}\", f\"image-{no}_mask-{mask}_00001_.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_list = []\n",
    "# for i in range(1, 3701):\n",
    "#     for j in range(SPLIT-1):\n",
    "#         if (f\"image-{i}_mask-{j}_00001_.png\") not in files:\n",
    "#             if i not in missing_list:\n",
    "#                 missing_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logits calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = {}\n",
    "\n",
    "# for i in range(MODEL_NUMBER):\n",
    "#     logits[i] = []\n",
    "\n",
    "# for group in tqdm(groups):\n",
    "#     for i, file in enumerate(group):\n",
    "#         subject_img = cv2.imread(os.path.join(generate_path, f\"image-{int(file.split('.')[0])}.jpg_00001_.png\"), cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "#         idx = int(file.split('.')[0])\n",
    "#         # plt.imshow(subject_img)\n",
    "#         # plt.show()\n",
    "#         # print(idx)\n",
    "#         sequence = []\n",
    "#         # each mask strip\n",
    "#         for mask_idx in range(SPLIT - 1):\n",
    "#             generated_img = cv2.imread(os.path.join(generate_path, f\"image-{idx}_mask-{mask_idx}_00001_.png\"), cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "#             # one strip\n",
    "#             columns = WIDTH // SPLIT * (mask_idx + 1)\n",
    "#             token = np.array(generated_img[:, columns:columns + WIDTH // SPLIT], dtype=np.int16)\n",
    "#             ground_truth = np.array(subject_img[:, columns:columns + WIDTH // SPLIT], dtype=np.int16)\n",
    "\n",
    "#             mse = ((token - ground_truth) ** 2).mean()\n",
    "#             sequence.append(mse)\n",
    "#         logits[i].append(sequence)\n",
    "\n",
    "# with open(\"./logits.json\", \"w\") as f:\n",
    "#     json.dump(logits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./logits.json\", \"r\") as f:\n",
    "    logits = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranking clac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_avgs = {}\n",
    "rank_var = {}\n",
    "\n",
    "for i in range(MODEL_NUMBER):\n",
    "    rank_avgs[i] = np.mean(rank_lists[i])\n",
    "    rank_var[i] = np.var(rank_lists[i])\n",
    "\n",
    "print(rank_avgs)\n",
    "print(rank_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_sum = []\n",
    "spectra = []\n",
    "for idx, winner in enumerate(winners):\n",
    "    logits_sum.append(logits[str(winner)][idx])\n",
    "    spectra.append(np.abs(np.fft.fft(logits[str(winner)][idx])))\n",
    "\n",
    "logits_winner_avg = np.mean(logits_sum, axis=0)\n",
    "spectrum_winner_avg = np.mean(spectra, axis=0)\n",
    "# print(logits_winner_avg)\n",
    "# print(spectrum_winner_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_logits = {}\n",
    "fig_size = (15, 10)\n",
    "\n",
    "plt.figure(0, fig_size)\n",
    "plt.plot(np.linspace(0, len(logits_winner_avg), len(logits_winner_avg)), logits_winner_avg, label=\"winner avg\", color=\"grey\")\n",
    "plt.legend()\n",
    "\n",
    "spectrum_winner_avg = spectrum_winner_avg[1:]\n",
    "\n",
    "plt.figure(1, fig_size)\n",
    "plt.plot(np.linspace(0, 0.5, len(spectrum_winner_avg)), spectrum_winner_avg, label=\"winner avg\", color=\"grey\")\n",
    "plt.legend()\n",
    "\n",
    "X = np.linspace(0, 0.5, len(spectrum_winner_avg))\n",
    "gam = LinearGAM().fit(X, spectrum_winner_avg)\n",
    "XX = gam.generate_X_grid(term=0, n=len(spectra))\n",
    "pdep, confi = gam.partial_dependence(term=0, X=XX, width=0.95)\n",
    "\n",
    "# XX =       XX[10:]\n",
    "# pdep =   pdep[10:]\n",
    "# confi = confi[10:]\n",
    "\n",
    "plt.figure(2, fig_size)\n",
    "plt.plot(\n",
    "    XX[:, 0],\n",
    "    np.abs(pdep),\n",
    "    label=\"winner avg\",\n",
    "    color=\"grey\"\n",
    ")\n",
    "# plt.fill_between(\n",
    "#     XX[:, 0],\n",
    "#     np.where(\n",
    "#         confi[:, 0] * confi[:, 1] > 0,\n",
    "#         np.minimum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "#         0\n",
    "#     ),\n",
    "#     np.maximum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "#     alpha=0.25\n",
    "# )\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "for i, logit_list in logits.items():\n",
    "    # print(len(logit_list[0]))\n",
    "    # break\n",
    "    avg_logits[i] = np.mean(logit_list, axis=0)\n",
    "\n",
    "    plt.figure(0, fig_size)\n",
    "    plt.title(\"Raw MSEs\")\n",
    "    plt.plot(np.linspace(0, len(avg_logits[i]), len(avg_logits[i])), avg_logits[i], label=f\"avg: {rank_avgs[int(i)]:.3}, var: {rank_var[int(i)]:.3}\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    spectra = []\n",
    "    for line in logit_list:\n",
    "        spectrum = np.abs(np.fft.fft(line))\n",
    "        spectra.append(spectrum)\n",
    "    mean_spectrum = np.mean(spectra, axis=0)\n",
    "\n",
    "    mean_spectrum = mean_spectrum[1:]\n",
    "\n",
    "    plt.figure(1, fig_size)\n",
    "    plt.title(\"Raw Spectra\")\n",
    "    plt.plot(np.linspace(0, 0.5, len(mean_spectrum)), mean_spectrum, label=f\"avg: {rank_avgs[int(i)]:.3}, var: {rank_var[int(i)]:.3}\")\n",
    "    plt.legend()\n",
    "\n",
    "    X = np.linspace(0, 0.5, len(mean_spectrum))\n",
    "    gam = LinearGAM().fit(X, mean_spectrum)\n",
    "    XX = gam.generate_X_grid(term=0, n=len(spectra))\n",
    "    pdep, confi = gam.partial_dependence(term=0, X=XX, width=0.95)\n",
    "\n",
    "    # XX =       XX[10:]\n",
    "    # pdep =   pdep[10:]\n",
    "    # confi = confi[10:]\n",
    "\n",
    "    plt.figure(2, fig_size)\n",
    "    plt.title(\"GAM Spectra\")\n",
    "    plt.plot(\n",
    "        XX[:, 0],\n",
    "        np.abs(pdep),\n",
    "        label=f\"avg: {rank_avgs[int(i)]:.3}, var: {rank_var[int(i)]:.3}\",\n",
    "    )\n",
    "    # plt.fill_between(\n",
    "    #     XX[:, 0],\n",
    "    #     np.where(\n",
    "    #         confi[:, 0] * confi[:, 1] > 0,\n",
    "    #         np.minimum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "    #         0\n",
    "    #     ),\n",
    "    #     np.maximum(np.abs(confi[:, 0]), np.abs(confi[:, 1])),\n",
    "    #     alpha=0.25\n",
    "    # )\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def spectral_overlap(spectrum1, spectrum2):\n",
    "    spectra = np.concatenate([spectrum1[None], spectrum2[None]], axis=0)\n",
    "    return spectra.min(axis=0).sum() / spectra.max(axis=0).sum()\n",
    "\n",
    "def pearson_correlation(spectrum1, spectrum2):\n",
    "    return np.corrcoef(spectrum1, spectrum2)[0, 1]\n",
    "\n",
    "def earth_mover_distance(spectrum1, spectrum2):\n",
    "    p1 = [spectrum1[0]]\n",
    "    p2 = [spectrum2[0]]\n",
    "    for value in spectrum1[1:]:\n",
    "        p1.append(p1[-1] + value)\n",
    "    for value in spectrum2[1:]:\n",
    "        p2.append(p2[-1] + value)\n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    p1 /= p1[-1]\n",
    "    p2 /= p2[-1]\n",
    "    return np.abs(p1 - p2).sum() / spectrum1.shape[0]\n",
    "\n",
    "def kl_divergence(spectrum1, spectrum2):\n",
    "    kl = entropy(abs(spectrum1), abs(spectrum2))\n",
    "    return kl\n",
    "\n",
    "def score(spectrum1, spectrum2):\n",
    "    so = spectral_overlap(spectrum1, spectrum2)\n",
    "    corr = pearson_correlation(spectrum1, spectrum2)\n",
    "    emd = earth_mover_distance(spectrum1, spectrum2)\n",
    "    kl = kl_divergence(spectrum1, spectrum2)\n",
    "    return so, corr, emd, kl\n",
    "\n",
    "def area_under_curve(spectrum):\n",
    "    return np.abs(spectrum).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_so_list = []\n",
    "mean_corr_list = []\n",
    "mean_emd_list = []\n",
    "mean_kl_list = []\n",
    "\n",
    "so_lists = []\n",
    "corr_lists = []\n",
    "emd_lists = []\n",
    "kl_lists = []\n",
    "\n",
    "# so_counters = {}\n",
    "# corr_counters = {}\n",
    "# emd_counters = {}\n",
    "# kl_counters = {}\n",
    "# for i in range(MODEL_NUMBER):\n",
    "#     so_counters[i] = {}\n",
    "#     corr_counters[i] = {}\n",
    "#     emd_counters[i] = {}\n",
    "#     kl_counters[i] = {}\n",
    "#     for j in range(MODEL_NUMBER):\n",
    "#         so_counters[i][j] = 0\n",
    "#         corr_counters[i][j] = 0\n",
    "#         emd_counters[i][j] = 0\n",
    "#         kl_counters[i][j] = 0\n",
    "\n",
    "for i, logit_list in logits.items():\n",
    "    # print(len(logit_list[0]))\n",
    "    # break\n",
    "    avg_logits[i] = np.mean(logit_list, axis=0)\n",
    "\n",
    "    so_list = []\n",
    "    corr_list = []\n",
    "    emd_list = []\n",
    "    kl_list = []\n",
    "\n",
    "    for line in logit_list:\n",
    "        spectrum = np.abs(np.fft.fft(line))\n",
    "        so, corr, emd, kl = score(spectrum_winner_avg, spectrum[1:])\n",
    "        so_list.append(so)\n",
    "        corr_list.append(corr)\n",
    "        emd_list.append(emd)\n",
    "        kl_list.append(kl)\n",
    "\n",
    "    so_lists.append(so_list)\n",
    "    corr_lists.append(corr_list)\n",
    "    emd_lists.append(emd_list)\n",
    "    kl_lists.append(kl_list)\n",
    "\n",
    "    # stepwise mean scores\n",
    "    mean_so = np.mean(so_list)\n",
    "    mean_corr = np.mean(corr_list)\n",
    "    mean_emd = np.mean(emd_list)\n",
    "    mean_kl = np.mean(kl_list)\n",
    "\n",
    "    mean_so_list.append(mean_so)\n",
    "    mean_corr_list.append(mean_corr)\n",
    "    mean_emd_list.append(mean_emd)\n",
    "    mean_kl_list.append(mean_kl)\n",
    "\n",
    "    print(f\"SO: {mean_so:.5}\\tCORR: {mean_corr:.5}\\tEMD: {mean_emd:.5}\\tKL: {mean_kl:.5}\")\n",
    "\n",
    "# stepwise rankings mean\n",
    "so_ranks_idx = np.argsort(-np.array(so_lists), axis=0)\n",
    "corr_ranks_idx = np.argsort(-np.array(corr_lists), axis=0)\n",
    "emd_ranks_idx = np.argsort(np.array(emd_lists), axis=0)\n",
    "kl_ranks_idx = np.argsort(np.array(kl_lists), axis=0)\n",
    "so_ranks_stepwise = np.zeros(so_ranks_idx.shape)\n",
    "corr_ranks_stepwise = np.zeros(corr_ranks_idx.shape)\n",
    "emd_ranks_stepwise = np.zeros(emd_ranks_idx.shape)\n",
    "kl_ranks_stepwise = np.zeros(kl_ranks_idx.shape)\n",
    "for j in range(so_ranks_idx.shape[1]):\n",
    "    for i in range(so_ranks_idx.shape[0]):\n",
    "        so_ranks_stepwise[so_ranks_idx[i][j]][j] = i\n",
    "        corr_ranks_stepwise[corr_ranks_idx[i][j]][j] = i\n",
    "        emd_ranks_stepwise[emd_ranks_idx[i][j]][j] = i\n",
    "        kl_ranks_stepwise[kl_ranks_idx[i][j]][j] = i\n",
    "\n",
    "print('='*10 + \" stepwise rankings \" + '='*10)\n",
    "\n",
    "for i in range(so_ranks_stepwise.shape[0]):\n",
    "    print(f\"AVG: {(np.mean(so_ranks_stepwise[i])+np.mean(corr_ranks_stepwise[i])+np.mean(emd_ranks_stepwise[i])+np.mean(kl_ranks_stepwise[i]))/4:.3}\\tSO: {np.mean(so_ranks_stepwise[i]):.3}\\tCORR: {np.mean(corr_ranks_stepwise[i]):.3}\\tEMD: {np.mean(emd_ranks_stepwise[i]):.3}\\tKL: {np.mean(kl_ranks_stepwise[i]):.3}\")\n",
    "\n",
    "# mean scores ranking\n",
    "so_ranks_idx = np.argsort(-np.array(mean_so_list))\n",
    "corr_ranks_idx = np.argsort(-np.array(mean_corr_list))\n",
    "emd_ranks_idx = np.argsort(mean_emd_list)\n",
    "kl_ranks_idx = np.argsort(mean_kl_list)\n",
    "so_ranks = np.zeros((len(so_ranks_idx)))\n",
    "corr_ranks = np.zeros((len(corr_ranks_idx)))\n",
    "emd_ranks = np.zeros((len(emd_ranks_idx)))\n",
    "kl_ranks = np.zeros((len(kl_ranks_idx)))\n",
    "for i in range(len(so_ranks_idx)):\n",
    "    so_ranks[so_ranks_idx[i]] = i\n",
    "    corr_ranks[corr_ranks_idx[i]] = i\n",
    "    emd_ranks[emd_ranks_idx[i]] = i\n",
    "    kl_ranks[kl_ranks_idx[i]] = i\n",
    "\n",
    "print('='*10 + \" rankings \" + '='*10)\n",
    "\n",
    "for i in range(len(so_ranks)):\n",
    "    print(f\"AVG: {(so_ranks[i]+corr_ranks[i]+emd_ranks[i]+kl_ranks[i])/4}\\tSO: {so_ranks[i]}\\tCORR: {corr_ranks[i]}\\tEMD: {emd_ranks[i]}\\tKL: {kl_ranks[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inception score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "from torchvision.models.inception import inception_v3\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# we should use same mean and std for inception v3 model in training and testing process\n",
    "# reference web page: https://pytorch.org/hub/pytorch_vision_inception_v3/\n",
    "\n",
    "def imread(filename):\n",
    "    \"\"\"\n",
    "    Loads an image file into a (height, width, 3) uint8 ndarray.\n",
    "    \"\"\"\n",
    "    return np.asarray(Image.open(filename), dtype=np.uint8)[..., :3]\n",
    "\n",
    "def inception_score(path, batch_size=50, resize=False, splits=10):\n",
    "    # Set up dtype\n",
    "    device = torch.device(\"cuda:1\")  # you can change the index of cuda\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.eval()\n",
    "    up = nn.Upsample(size=(299, 299), mode='nearest', align_corners=False).to(device)\n",
    "    \n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x, dim=1).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions using pre-trained inception_v3 model\n",
    "    print('Computing predictions using inception v3 model')\n",
    "    \n",
    "\n",
    "    files = readDir(path)\n",
    "    N = len(files)\n",
    "    preds = np.zeros((N, 1000))\n",
    "    if batch_size > N:\n",
    "        print(('Warning: batch size is bigger than the data size. '\n",
    "                 'Setting batch size to data size'))\n",
    "\n",
    "    for i in tqdm(range(0, N, batch_size)):\n",
    "        start = i\n",
    "        end = i + batch_size\n",
    "        images = np.array([imread(str(f)).astype(np.float32)\n",
    "                           for f in files[start:end]])\n",
    "\n",
    "        # Reshape to (n_images, 3, height, width)\n",
    "        images = images.transpose((0, 3, 1, 2))\n",
    "        images /= 255\n",
    "\n",
    "        batch = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "        batch = batch.to(device)\n",
    "        y = get_pred(batch)\n",
    "        # print(y.shape)\n",
    "        preds[i :i  + batch_size] = get_pred(batch)\n",
    "        \n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Now compute the mean KL Divergence\n",
    "    print('Computing KL Divergence')\n",
    "    split_scores = []\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k + 1) * (N // splits), :] # split the whole data into several parts\n",
    "        py = np.mean(part, axis=0)  # marginal probability\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]  # conditional probability\n",
    "            scores.append(entropy(pyx, py))  # compute divergence\n",
    "        split_scores.append(np.exp(scores))\n",
    "\n",
    "    return split_scores\n",
    "\n",
    "def readDir(path):\n",
    "    allFiles = []\n",
    "    if os.path.isdir(path):\n",
    "        fileList = os.listdir(path)\n",
    "        for f in fileList:\n",
    "            f = path+'/'+f\n",
    "            if os.path.isdir(f):\n",
    "                subFiles = readDir(f)\n",
    "                allFiles = subFiles + allFiles\n",
    "            else:\n",
    "                allFiles.append(f)\n",
    "        return allFiles\n",
    "    else:\n",
    "        return 'Error,not a dir'\n",
    "\n",
    "inception_scores = {}\n",
    "for i in range(MODEL_NUMBER):\n",
    "    scores = inception_score(path = f\"/home/lyy/Repos/FACE-image/data/model_{i}\", splits=211)\n",
    "    inception_scores[i] = scores\n",
    "    print(f\"model {i}:\\tmax: {np.max(scores)}\\tmean: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(inception_scores))\n",
    "# print(len(inception_scores[0]))\n",
    "\n",
    "# # for idx, values in inception_scores.items():\n",
    "# #     inception_scores[idx] = [value.tolist() for value in values]\n",
    "\n",
    "# with open(\"../data/inception_scores.json\", \"w\") as f:\n",
    "#     json.dump(inception_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_scores = {}\n",
    "with open(\"../data/inception_scores.json\", \"r\") as f:\n",
    "    inception_scores = json.load(f)\n",
    "\n",
    "inception_rankings = []\n",
    "for idx in range(len(inception_scores['0'])):\n",
    "    scores = []\n",
    "    for model in range(MODEL_NUMBER):\n",
    "        scores.append(np.mean(inception_scores[str(model)][idx]))\n",
    "    rank_idxes = np.argsort(scores)\n",
    "    ranking = np.zeros((len(rank_idxes)))\n",
    "    for i, rank_idx in enumerate(rank_idxes):\n",
    "        ranking[rank_idx] = i\n",
    "    inception_rankings.append(ranking)\n",
    "inception_rankings = np.array(inception_rankings)\n",
    "print(inception_rankings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "histSize = 256\n",
    "histRange = (0, 256)\n",
    "accumulate = False\n",
    "\n",
    "hist_groups = []\n",
    "for names in groups:\n",
    "    b_hists = []\n",
    "    g_hists = []\n",
    "    r_hists = []\n",
    "    for name in names:\n",
    "        image = cv.imread(os.path.join(hpd_path, name), cv.IMREAD_COLOR)\n",
    "        bgr_planes = cv.split(image)\n",
    "        b_hist = cv.calcHist(bgr_planes, [0], None, [histSize], histRange, accumulate=accumulate)\n",
    "        g_hist = cv.calcHist(bgr_planes, [1], None, [histSize], histRange, accumulate=accumulate)\n",
    "        r_hist = cv.calcHist(bgr_planes, [2], None, [histSize], histRange, accumulate=accumulate)\n",
    "        b_hists.append(b_hist)\n",
    "        g_hists.append(g_hist)\n",
    "        r_hists.append(r_hist)\n",
    "        # print(name)\n",
    "        # plt.imshow(image[:,:,::-1])\n",
    "        # plt.show()\n",
    "        # plt.plot(b_hist, color=\"blue\", label=\"b hist\")\n",
    "        # plt.plot(g_hist, color=\"green\", label=\"g hist\")\n",
    "        # plt.plot(r_hist, color=\"red\", label=\"r hist\")\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "    hist_groups.append((b_hists, g_hists, r_hists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_hists = []\n",
    "for idx, hist_group in enumerate(hist_groups):\n",
    "    winner_hists.append([hist_group[0][winners[idx]], hist_group[1][winners[idx]], hist_group[2][winners[idx]]])\n",
    "\n",
    "winner_hists = np.array(winner_hists)\n",
    "mean_winner_hist = np.mean(winner_hists, axis=0)\n",
    "plt.plot(mean_winner_hist[0], color=\"blue\", label=\"blue hist\")\n",
    "plt.plot(mean_winner_hist[1], color=\"green\", label=\"green hist\")\n",
    "plt.plot(mean_winner_hist[2], color=\"red\", label=\"red hist\")\n",
    "plt.legend()\n",
    "\n",
    "HIST_METHOD = cv.HISTCMP_CORREL\n",
    "model_scores = [[] for _ in range(MODEL_NUMBER)]\n",
    "hist_ranks = []\n",
    "for idx, hist_group in enumerate(hist_groups):\n",
    "    group_scores = [[] for _ in range(MODEL_NUMBER)]\n",
    "    for channel, channel_group in enumerate(hist_group):\n",
    "        for model, hist in enumerate(channel_group):\n",
    "            diff = cv.compareHist(mean_winner_hist[channel], hist, HIST_METHOD)\n",
    "            model_scores[model].append(diff)\n",
    "            group_scores[model].append(diff)\n",
    "    group_scores = np.array(group_scores)\n",
    "    rank_idxes = np.argsort(group_scores, axis=0)\n",
    "    group_ranks = np.zeros(rank_idxes.shape)\n",
    "    for channel in range(3):\n",
    "        for rank, model in enumerate(rank_idxes[:, channel]):\n",
    "            group_ranks[model, channel] = rank\n",
    "    mean_group_ranks = np.mean(group_ranks, axis=1)\n",
    "    hist_ranks.append(mean_group_ranks)\n",
    "\n",
    "hist_ranks = np.array(hist_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corr coe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "human_ranks = np.zeros((len(rank_lists[0]), MODEL_NUMBER))\n",
    "for i in range(len(rank_lists[0])):\n",
    "    for j in range(MODEL_NUMBER):\n",
    "        human_ranks[i, j] = rank_lists[j][i]\n",
    "\n",
    "# compared human ranks\n",
    "compared_ranks = [0, 4, 8]\n",
    "\n",
    "def calc_corr(human_line, score_line):\n",
    "    human_compared_line = []\n",
    "    score_compared_line = []\n",
    "    for no, item in enumerate(human_line):\n",
    "        if item in compared_ranks:\n",
    "            human_compared_line.append(human_line[no])\n",
    "            score_compared_line.append(score_line[no])\n",
    "    return spearmanr(np.array(human_compared_line), np.array(score_compared_line))\n",
    "\n",
    "# SO stepwise\n",
    "corr_coes = []\n",
    "p_values = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = so_ranks_stepwise.T[idx]\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"SO:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")\n",
    "\n",
    "# CORR stepwise\n",
    "corr_coes = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = corr_ranks_stepwise.T[idx]\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"CORR:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")\n",
    "\n",
    "# EMD stepwise\n",
    "corr_coes = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = emd_ranks_stepwise.T[idx]\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"EMD:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")\n",
    "\n",
    "# KL stepwise\n",
    "corr_coes = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = kl_ranks_stepwise.T[idx]\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"KL:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")\n",
    "\n",
    "# avg stepwise\n",
    "corr_coes = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = (so_ranks_stepwise.T[idx] + corr_ranks_stepwise.T[idx] + emd_ranks_stepwise.T[idx] + kl_ranks_stepwise.T[idx]) / 4\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"AVG:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")\n",
    "\n",
    "# inception score\n",
    "corr_coes = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = inception_rankings[idx]\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"IS:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")\n",
    "\n",
    "# image histogram\n",
    "corr_coes = []\n",
    "for idx in range(len(rank_lists[0])):\n",
    "    human_line = human_ranks[idx]\n",
    "    score_line = hist_ranks[idx]\n",
    "    corr_line, p_line = calc_corr(human_line, score_line)\n",
    "    corr_coes.append(corr_line)\n",
    "    p_values.append(p_line)\n",
    "print(f\"HIST:\\t{np.mean(corr_coes):.4}\\t{np.mean(p_values):.4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
